{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wTvSZ1Em0lRw"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import gc\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.optimizers import Adam\n",
        "from keras.applications import DenseNet121,DenseNet169,DenseNet201"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# connecting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# change to project directory\n",
        "%cd /content/drive/My\\ Drive/AI4ALL\\ Diabetic\\ Retinopathy\\ Research/Early\\ ML\\ Model/aptos2019-blindness-detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAXcJWnj-yZ2",
        "outputId": "437d0df7-0e92-4bbf-dcab-b5591a15424d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/.shortcut-targets-by-id/1DwcsYZWFxUskq7gNIgNqPDzvPfHJSdsh/AI4ALL Diabetic Retinopathy Research/Early ML Model/aptos2019-blindness-detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train1 = np.load('x_train1.npy')\n",
        "y_train1 = np.load('y_train1.npy')"
      ],
      "metadata": {
        "id": "6rUdjv641GlP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_sptrain, x_spval, y_sptrain, y_spval = train_test_split(\n",
        "    x_train1, y_train1,\n",
        "    random_state=42\n",
        ")\n",
        "print(\"train-validation splitted ...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vRUScTK1Kg4",
        "outputId": "356923fb-e170-4470-a5ad-269eeb742817"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train-validation splitted ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del x_train1,y_train1\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQvWYF3u1MEH",
        "outputId": "59c247f6-1c57-47d8-97d1-44c8de9de3aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_sptrain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jkw2It4Z9T5j",
        "outputId": "a0c81f76-0bd2-4850-9c9c-0b5efd94d285"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True,  True,  True, False, False],\n",
              "       [ True, False, False, False, False],\n",
              "       [ True,  True,  True,  True,  True],\n",
              "       ...,\n",
              "       [ True,  True,  True, False, False],\n",
              "       [ True,  True, False, False, False],\n",
              "       [ True, False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "def create_datagen():\n",
        "    return ImageDataGenerator(\n",
        "         horizontal_flip=True,   # randomly flip images\n",
        "         vertical_flip=True,     # randomly flip images\n",
        "         rotation_range=20 ,      # Degree range for random rotations\n",
        "         zoom_range=0.1\n",
        "\n",
        "    )\n",
        "\n",
        "# Using original generator\n",
        "data_generator = create_datagen().flow(x_sptrain, y_sptrain,batch_size=8,seed=20031976)\n",
        "print(x_sptrain.shape)\n",
        "print(\"Image data augmentated ...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL4s1e4C1PJO",
        "outputId": "3c1db994-c227-419d-ebb5-6a4922ad8e90"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2746, 256, 256, 3)\n",
            "Image data augmentated ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "def f1(y_true, y_pred):\n",
        "    y_pred = K.round(y_pred)\n",
        "    print(\"test\")\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2*p*r / (p+r+K.epsilon())\n",
        "    print(\"im here\")\n",
        "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return K.mean(f1)"
      ],
      "metadata": {
        "id": "44wcMDXW1Q7x"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdMbL3hR1Svz",
        "outputId": "4496d758-2a39-4275-91d8-79f077f76775"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "effnet = DenseNet121(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(256,256,3)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBaddrKs1UZq",
        "outputId": "551c1a05-4122-4617-dd35-e8ef616adff1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29084464/29084464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(effnet)\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1024,activation='relu'))\n",
        "model.add(layers.Dense(5, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.00005), metrics=['accuracy',f1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tL70DYnN1WZC",
        "outputId": "9c584315-c17c-4aff-9418-a0d1e120e813"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXB947kj1Yp0",
        "outputId": "30dbf1c6-ec70-4148-b1b7-02299930e8cf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14385"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# callback to keep track of kappa score during training\n",
        "from keras.callbacks import Callback,ModelCheckpoint\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "import json\n",
        "class KappaMetrics(Callback):\n",
        "    i=0\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.val_kappas = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        X_val, y_val = self.validation_data[:2]\n",
        "        y_val = y_val.sum(axis=1) - 1\n",
        "\n",
        "        y_pred = self.model.predict(X_val) > 0.5\n",
        "        y_pred = y_pred.astype(int).sum(axis=1) - 1\n",
        "\n",
        "        _val_kappa = cohen_kappa_score(\n",
        "            y_val,\n",
        "            y_pred,\n",
        "            weights='quadratic'\n",
        "        )\n",
        "\n",
        "        self.val_kappas.append(_val_kappa)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1} val_kappa: {_val_kappa:.4f}\")\n",
        "        if _val_kappa == max(self.val_kappas):\n",
        "            print(\"Validation Kappa has improved. Saving model. - \"+str(KappaMetrics.i))\n",
        "            model_json = self.model.to_json()\n",
        "            with open(\"model_in_json\"+str(KappaMetrics.i)+\".json\", \"w\") as json_file:\n",
        "                json.dump(model_json, json_file)\n",
        "            self.model.save_weights(\"model_weights\"+str(KappaMetrics.i)+\".h5\")\n",
        "            KappaMetrics.i+=1\n",
        "        print('im here')\n",
        "        return\n",
        "\n",
        "kappa_score = KappaMetrics()"
      ],
      "metadata": {
        "id": "9p7ZcloC1aAk"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_spval.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBoXDVN4ASIV",
        "outputId": "00c86639-f97f-4d3b-dfeb-0526608cc4b7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "180092928"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    data_generator,\n",
        "    validation_data=(x_spval, y_spval),\n",
        "    steps_per_epoch= 3362/8,\n",
        "    epochs=8,\n",
        "    callbacks=[kappa_score]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "2RoyvsRD1cyN",
        "outputId": "e31a3459-1d7c-4475-9803-3fe22ddd1ed1"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "419/420 [============================>.] - ETA: 0s"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unexpected result of `train_function` (Empty logs). This could be due to issues in input pipeline that resulted in an empty dataset. Otherwise, please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-3a445d253983>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdata_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_spval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_spval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m3362\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1817\u001b[0m                 \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1818\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1819\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m   1820\u001b[0m                         \u001b[0;34m\"Unexpected result of `train_function` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m                         \u001b[0;34m\"(Empty logs). This could be due to issues in input \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unexpected result of `train_function` (Empty logs). This could be due to issues in input pipeline that resulted in an empty dataset. Otherwise, please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['Train_Loss','Validation_Loss'])"
      ],
      "metadata": {
        "id": "cLDrz_1z1fH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.legend(['Train_Accuracy','Validation_Accuracy'])"
      ],
      "metadata": {
        "id": "nziZypPd1jYY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}